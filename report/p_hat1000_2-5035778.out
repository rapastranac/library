
Lmod is automatically replacing "intel/2020.1.217" with "gcc/10.2.0".


Inactive Modules:
  1) libfabric/1.10.1     2) openmpi/4.0.3     3) ucx/1.8.0

The following have been reloaded with a version change:
  1) gcccore/.9.3.0 => gcccore/.10.2.0


Activating Modules:
  1) libfabric/1.10.1     2) openmpi/4.0.5     3) ucx/1.9.0


Currently Loaded Modules:
  1) CCEnv           (S)      5) StdEnv/2020     (S)   9) pmix/3.1.5
  2) CCconfig                 6) gcccore/.10.2.0 (H)  10) libfabric/1.10.1
  3) gentoo/2020     (S)      7) gcc/10.2.0      (t)  11) openmpi/4.0.5    (m)
  4) imkl/2020.1.217 (math)   8) ucx/1.9.0

  Where:
   H:     Hidden Module
   S:     Module is Sticky, requires --force to unload or purge
   m:     MPI implementations / Implémentations MPI
   math:  Mathematical libraries / Bibliothèques mathématiques
   t:     Tools for development / Outils de développement

 

Current working directory: /gpfs/fs0/scratch/m/mlafond/pasr1602/library
Starting run at: Tue Mar 23 13:21:47 EDT 2021
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 0 of 5 is on nia1192.scinet.local
Seed sent 
Termination achieved: nodes 4, busy 0 
solution received from 1, Bytes : 3864, refVal 946 
solution received from 2, Bytes : 3868, refVal 947 
solution received from 3, Bytes : 3948, refVal 967 
solution received from 4, Bytes : 4024, refVal 986 

 
 
*****************************************************
Elapsed time : 10434.864 
Total number of requests : 95315 
Number of approved requests : 40550 
Number of failed requests : 54765 
*****************************************************

 
 
Stream retrieved, size : 3864 
Cover size : 946 

Global pool idle time: 1771.301117 seconds


argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 4 of 5 is on nia1398.scinet.local
rank 4 synchronised, num nodes = 4 
VC = 986......process 4, thread 2, Tue Mar 23 13:22:00 2021
rank 4 updated refValueGlobalAbsolute to 986 || 986 
rank 4, buffer size to be sent : 4024 
Exit tag received on process 4 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 3 of 5 is on nia1259.scinet.local
rank 3 synchronised, num nodes = 4 
VC = 984......process 3, thread 0, Tue Mar 23 13:22:00 2021
rank 3 updated refValueGlobalAbsolute to 984 || 984 
rank 3, buffer size to be sent : 4016 
VC = 983......process 3, thread 5, Tue Mar 23 13:22:00 2021
rank 3 updated refValueGlobalAbsolute to 983 || 983 
rank 3, buffer size to be sent : 4012 
VC = 982.....process 3, thread 34, Tue Mar 23 13:22:00 2021
rank 3 updated refValueGlobalAbsolute to 982 || 982 
rank 3, buffer size to be sent : 4008 
VC = 980.....process 3, thread 20, Tue Mar 23 13:22:00 2021
rank 3 updated refValueGlobalAbsolute to 980 || 980 
rank 3, buffer size to be sent : 4000 
VC = 979.....process 3, thread 26, Tue Mar 23 13:22:00 2021
rank 3 updated refValueGlobalAbsolute to 979 || 979 
rank 3, buffer size to be sent : 3996 
VC = 977......process 3, thread 3, Tue Mar 23 13:22:00 2021
rank 3 updated refValueGlobalAbsolute to 977 || 977 
rank 3, buffer size to be sent : 3988 
VC = 975......process 3, thread 8, Tue Mar 23 13:22:00 2021
rank 3 updated refValueGlobalAbsolute to 975 || 975 
rank 3, buffer size to be sent : 3980 
VC = 973.....process 3, thread 15, Tue Mar 23 13:22:00 2021
rank 3 updated refValueGlobalAbsolute to 973 || 973 
rank 3, buffer size to be sent : 3972 
VC = 971.....process 3, thread 14, Tue Mar 23 13:22:00 2021
rank 3 updated refValueGlobalAbsolute to 971 || 971 
rank 3, buffer size to be sent : 3964 
VC = 970.....process 3, thread 29, Tue Mar 23 13:22:00 2021
rank 3 updated refValueGlobalAbsolute to 970 || 970 
rank 3, buffer size to be sent : 3960 
VC = 968.....process 3, thread 37, Tue Mar 23 13:22:00 2021
rank 3 updated refValueGlobalAbsolute to 968 || 968 
rank 3, buffer size to be sent : 3952 
VC = 967.....process 3, thread 37, Tue Mar 23 13:22:00 2021
rank 3 updated refValueGlobalAbsolute to 967 || 967 
rank 3, buffer size to be sent : 3948 
Exit tag received on process 3 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 2 of 5 is on nia1256.scinet.local
rank 2 synchronised, num nodes = 4 
VC = 965.....process 2, thread 22, Tue Mar 23 13:22:01 2021
rank 2 updated refValueGlobalAbsolute to 965 || 965 
rank 2, buffer size to be sent : 3940 
VC = 964.....process 2, thread 22, Tue Mar 23 13:22:01 2021
rank 2 updated refValueGlobalAbsolute to 964 || 964 
rank 2, buffer size to be sent : 3936 
VC = 962.....process 2, thread 18, Tue Mar 23 13:22:01 2021
rank 2 updated refValueGlobalAbsolute to 962 || 962 
rank 2, buffer size to be sent : 3928 
VC = 949.....process 2, thread 15, Tue Mar 23 13:22:14 2021
rank 2 updated refValueGlobalAbsolute to 949 || 949 
rank 2, buffer size to be sent : 3876 
VC = 948.....process 2, thread 15, Tue Mar 23 13:22:23 2021
rank 2 updated refValueGlobalAbsolute to 948 || 948 
rank 2, buffer size to be sent : 3872 
VC = 947.....process 2, thread 15, Tue Mar 23 13:30:14 2021
rank 2 updated refValueGlobalAbsolute to 947 || 947 
rank 2, buffer size to be sent : 3868 
Exit tag received on process 2 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 1 of 5 is on nia1251.scinet.local
rank 1 synchronised, num nodes = 4 
VC = 987......process 1, thread 2, Tue Mar 23 13:22:00 2021
rank 1 updated refValueGlobalAbsolute to 987 || 987 
rank 1, buffer size to be sent : 4028 
VC = 961.....process 1, thread 27, Tue Mar 23 13:22:01 2021
rank 1 updated refValueGlobalAbsolute to 961 || 961 
rank 1, buffer size to be sent : 3924 
VC = 946.....process 1, thread 26, Tue Mar 23 16:01:03 2021
rank 1 updated refValueGlobalAbsolute to 946 || 946 
rank 1, buffer size to be sent : 3864 
Exit tag received on process 1 
Finishing run at: Tue Mar 23 16:15:56 EDT 2021

scontrol show jobid 5035778
JobId=5035778 JobName=p_hat1000_2
   UserId=pasr1602(3102120) GroupId=mlafond(6054778) MCS_label=N/A
   Priority=2114239 Nice=0 Account=def-mlafond QOS=normal
   JobState=COMPLETING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=02:54:29 TimeLimit=05:00:00 TimeMin=N/A
   SubmitTime=2021-03-23T13:21:25 EligibleTime=2021-03-23T13:21:25
   AccrueTime=2021-03-23T13:21:25
   StartTime=2021-03-23T13:21:27 EndTime=2021-03-23T16:15:56 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2021-03-23T13:21:27
   Partition=compute AllocNode:Sid=nia-login07:209551
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=nia[1192,1251,1256,1259,1398]
   BatchHost=nia1192
   NumNodes=5 NumCPUs=400 NumTasks=5 CPUs/Task=40 ReqB:S:C:T=0:0:*:*
   TRES=cpu=400,mem=875000M,node=5,billing=200
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=40 MinMemoryNode=175000M MinTmpDiskNode=0
   Features=[skylake|cascade] DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/fs0/scratch/m/mlafond/pasr1602/library/job.sh
   WorkDir=/gpfs/fs0/scratch/m/mlafond/pasr1602/library
   StdErr=/gpfs/fs0/scratch/m/mlafond/pasr1602/library/report/p_hat1000_2-5035778.out
   StdIn=/dev/null
   StdOut=/gpfs/fs0/scratch/m/mlafond/pasr1602/library/report/p_hat1000_2-5035778.out
   Power=
   MailUser=pasr1602@usherbrooke.ca MailType=BEGIN,END,FAIL,REQUEUE

sacct -j 5035778
       JobID    JobName    Account    Elapsed  MaxVMSize     MaxRSS  SystemCPU    UserCPU ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- ---------- ---------- -------- 
5035778      p_hat1000+ def-mlafo+   02:54:29                         02:08:23 16-03:40:+      0:0 
5035778.bat+      batch def-mlafo+   02:54:29    724580K      9368K  00:01.282  00:03.603      0:0 
5035778.ext+     extern def-mlafo+   02:54:29    138360K       880K   00:00:00  00:00.004      0:0 
5035778.0         a.out def-mlafo+   02:54:06  13748004K  11330772K   02:08:22 16-03:40:+      0:0 

kernel messages produced during job executions:
[Mar23 14:54] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1cfcf
[  +0.011491] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1cfd0
[  +0.011448] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1cfd1
[  +0.011398] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1cfd2
[  +0.011379] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1cfd3
[  +0.043315] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1cfbf
[  +0.011361] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1cfc0
[  +0.011339] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1cfc1
[  +0.011331] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1cfc2
[  +0.011323] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1cfc3

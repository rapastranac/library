
Lmod is automatically replacing "intel/2020.1.217" with "gcc/10.2.0".


Inactive Modules:
  1) libfabric/1.10.1     2) openmpi/4.0.3     3) ucx/1.8.0

The following have been reloaded with a version change:
  1) gcccore/.9.3.0 => gcccore/.10.2.0


Activating Modules:
  1) libfabric/1.10.1     2) openmpi/4.0.5     3) ucx/1.9.0


Currently Loaded Modules:
  1) CCEnv           (S)      5) StdEnv/2020     (S)   9) pmix/3.1.5
  2) CCconfig                 6) gcccore/.10.2.0 (H)  10) libfabric/1.10.1
  3) gentoo/2020     (S)      7) gcc/10.2.0      (t)  11) openmpi/4.0.5    (m)
  4) imkl/2020.1.217 (math)   8) ucx/1.9.0

  Where:
   H:     Hidden Module
   S:     Module is Sticky, requires --force to unload or purge
   m:     MPI implementations / Implémentations MPI
   math:  Mathematical libraries / Bibliothèques mathématiques
   t:     Tools for development / Outils de développement

 

Current working directory: /gpfs/fs0/scratch/m/mlafond/pasr1602/library
Starting run at: Tue Mar 23 16:31:40 EDT 2021
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 0 of 10 is on nia0806.scinet.local
Seed sent 
Termination achieved: nodes 9, busy 0 
solution received from 1, Bytes : 3868, refVal 947 
solution received from 2, Bytes : 3924, refVal 961 
solution received from 3, Bytes : 3984, refVal 976 
solution received from 4, Bytes : 3972, refVal 973 
solution received from 5, Bytes : 3948, refVal 967 
solution received from 6, Bytes : 3980, refVal 975 
solution received from 7, Bytes : 3960, refVal 970 
solution received from 8, Bytes : 3864, refVal 946 
solution NOT received from rank 9

 
 
*****************************************************
Elapsed time : 4892.520 
Total number of requests : 233381 
Number of approved requests : 57785 
Number of failed requests : 175596 
*****************************************************

 
 
Stream retrieved, size : 3864 
Cover size : 946 

Global pool idle time: 1719.194563 seconds


argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 3 of 10 is on nia0876.scinet.local
rank 3 synchronised, num nodes = 9 
VC = 984......process 3, thread 0, Tue Mar 23 16:31:49 2021
rank 3 updated refValueGlobalAbsolute to 984 || 984 
rank 3, buffer size to be sent : 4016 
VC = 979.....process 3, thread 25, Tue Mar 23 16:31:49 2021
rank 3 updated refValueGlobalAbsolute to 979 || 979 
rank 3, buffer size to be sent : 3996 
VC = 977.....process 3, thread 37, Tue Mar 23 16:31:49 2021
rank 3 updated refValueGlobalAbsolute to 977 || 977 
rank 3, buffer size to be sent : 3988 
VC = 976.....process 3, thread 37, Tue Mar 23 16:31:49 2021
rank 3 updated refValueGlobalAbsolute to 976 || 976 
rank 3, buffer size to be sent : 3984 
Exit tag received on process 3 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 4 of 10 is on nia0890.scinet.local
rank 4 synchronised, num nodes = 9 
VC = 973.....process 4, thread 22, Tue Mar 23 16:31:49 2021
rank 4 updated refValueGlobalAbsolute to 973 || 973 
rank 4, buffer size to be sent : 3972 
Exit tag received on process 4 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 8 of 10 is on nia1170.scinet.local
rank 8 synchronised, num nodes = 9 
VC = 980......process 8, thread 5, Tue Mar 23 16:31:49 2021
rank 8 updated refValueGlobalAbsolute to 980 || 980 
rank 8, buffer size to be sent : 4000 
VC = 971.....process 8, thread 17, Tue Mar 23 16:31:49 2021
rank 8 updated refValueGlobalAbsolute to 971 || 971 
rank 8, buffer size to be sent : 3964 
VC = 946.....process 8, thread 26, Tue Mar 23 17:46:52 2021
rank 8 updated refValueGlobalAbsolute to 946 || 946 
rank 8, buffer size to be sent : 3864 
Exit tag received on process 8 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 9 of 10 is on nia1171.scinet.local
rank 9 synchronised, num nodes = 9 
Exit tag received on process 9 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 2 of 10 is on nia0872.scinet.local
rank 2 synchronised, num nodes = 9 
VC = 965.....process 2, thread 25, Tue Mar 23 16:31:50 2021
rank 2 updated refValueGlobalAbsolute to 965 || 965 
rank 2, buffer size to be sent : 3940 
VC = 964.....process 2, thread 25, Tue Mar 23 16:31:50 2021
rank 2 updated refValueGlobalAbsolute to 964 || 964 
rank 2, buffer size to be sent : 3936 
VC = 963.....process 2, thread 25, Tue Mar 23 16:31:50 2021
rank 2 updated refValueGlobalAbsolute to 963 || 963 
rank 2, buffer size to be sent : 3932 
VC = 961......process 2, thread 1, Tue Mar 23 16:31:52 2021
rank 2 updated refValueGlobalAbsolute to 961 || 961 
rank 2, buffer size to be sent : 3924 
Exit tag received on process 2 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 5 of 10 is on nia0928.scinet.local
rank 5 synchronised, num nodes = 9 
VC = 968......process 5, thread 2, Tue Mar 23 16:31:50 2021
rank 5 updated refValueGlobalAbsolute to 968 || 968 
rank 5, buffer size to be sent : 3952 
VC = 967......process 5, thread 2, Tue Mar 23 16:31:50 2021
rank 5 updated refValueGlobalAbsolute to 967 || 967 
rank 5, buffer size to be sent : 3948 
Exit tag received on process 5 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 7 of 10 is on nia1169.scinet.local
rank 7 synchronised, num nodes = 9 
VC = 970.....process 7, thread 30, Tue Mar 23 16:31:49 2021
rank 7 updated refValueGlobalAbsolute to 970 || 970 
rank 7, buffer size to be sent : 3960 
Exit tag received on process 7 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 6 of 10 is on nia1168.scinet.local
rank 6 synchronised, num nodes = 9 
VC = 987......process 6, thread 0, Tue Mar 23 16:31:49 2021
rank 6 updated refValueGlobalAbsolute to 987 || 987 
rank 6, buffer size to be sent : 4028 
VC = 975......process 6, thread 2, Tue Mar 23 16:31:49 2021
rank 6 updated refValueGlobalAbsolute to 975 || 975 
rank 6, buffer size to be sent : 3980 
Exit tag received on process 6 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 1 of 10 is on nia0855.scinet.local
rank 1 synchronised, num nodes = 9 
VC = 962.....process 1, thread 38, Tue Mar 23 16:31:51 2021
rank 1 updated refValueGlobalAbsolute to 962 || 962 
rank 1, buffer size to be sent : 3928 
VC = 949.....process 1, thread 29, Tue Mar 23 16:32:06 2021
rank 1 updated refValueGlobalAbsolute to 949 || 949 
rank 1, buffer size to be sent : 3876 
VC = 948.....process 1, thread 29, Tue Mar 23 16:32:17 2021
rank 1 updated refValueGlobalAbsolute to 948 || 948 
rank 1, buffer size to be sent : 3872 
VC = 947.....process 1, thread 29, Tue Mar 23 16:40:37 2021
rank 1 updated refValueGlobalAbsolute to 947 || 947 
rank 1, buffer size to be sent : 3868 
Exit tag received on process 1 
Finishing run at: Tue Mar 23 17:53:26 EDT 2021

scontrol show jobid 5037401
JobId=5037401 JobName=p_hat1000_2_10nodes
   UserId=pasr1602(3102120) GroupId=mlafond(6054778) MCS_label=N/A
   Priority=2029175 Nice=0 Account=def-mlafond QOS=normal
   JobState=COMPLETING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=01:22:08 TimeLimit=03:00:00 TimeMin=N/A
   SubmitTime=2021-03-23T16:19:59 EligibleTime=2021-03-23T16:19:59
   AccrueTime=2021-03-23T16:19:59
   StartTime=2021-03-23T16:31:20 EndTime=2021-03-23T17:53:28 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2021-03-23T16:31:20
   Partition=compute AllocNode:Sid=nia-login07:209551
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=nia[0806,0855,0872,0876,0890,0928,1168-1171]
   BatchHost=nia0806
   NumNodes=10 NumCPUs=800 NumTasks=10 CPUs/Task=40 ReqB:S:C:T=0:0:*:*
   TRES=cpu=800,mem=1750000M,node=10,billing=400
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=40 MinMemoryNode=175000M MinTmpDiskNode=0
   Features=[skylake|cascade] DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/fs0/scratch/m/mlafond/pasr1602/library/job.sh
   WorkDir=/gpfs/fs0/scratch/m/mlafond/pasr1602/library
   StdErr=/gpfs/fs0/scratch/m/mlafond/pasr1602/library/report/p_hat1000_2_10nodes-5037401.out
   StdIn=/dev/null
   StdOut=/gpfs/fs0/scratch/m/mlafond/pasr1602/library/report/p_hat1000_2_10nodes-5037401.out
   Power=
   MailUser=pasr1602@usherbrooke.ca MailType=BEGIN,END,FAIL,REQUEUE

sacct -j 5037401
       JobID    JobName    Account    Elapsed  MaxVMSize     MaxRSS  SystemCPU    UserCPU ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- ---------- ---------- -------- 
5037401      p_hat1000+ def-mlafo+   01:22:08                         02:27:19 16-21:10:+      0:0 
5037401.bat+      batch def-mlafo+   01:22:08   1057404K      9532K  00:01.300  00:03.649      0:0 
5037401.ext+     extern def-mlafo+   01:22:08    138360K      1068K  00:00.001  00:00.006      0:0 
5037401.0         a.out def-mlafo+   01:21:47  13618148K  11137580K   02:27:17 16-21:10:+      0:0 

kernel messages produced during job executions:
[Mar23 16:31] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x35575
[  +0.011492] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x35576
[  +0.011447] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x35577
[  +0.011401] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x35578
[  +0.011378] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x35579
[  +0.011370] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x3557a
[  +0.011352] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x3557b
[  +0.011342] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x3557c
[  +0.011333] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x3557d
[  +0.011325] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x3557e
[  +0.053948] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x35563
[  +0.011312] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x35564
[  +0.011291] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x35565
[  +0.011276] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x35566
[  +0.011261] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x35567
[  +0.011248] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x35568
[  +0.011234] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x35569
[  +0.011217] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x3557f
[  +0.011195] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x35580
[  +0.011175] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x35581

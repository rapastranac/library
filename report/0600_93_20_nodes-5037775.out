
Lmod is automatically replacing "intel/2020.1.217" with "gcc/10.2.0".


Inactive Modules:
  1) libfabric/1.10.1     2) openmpi/4.0.3     3) ucx/1.8.0

The following have been reloaded with a version change:
  1) gcccore/.9.3.0 => gcccore/.10.2.0


Activating Modules:
  1) libfabric/1.10.1     2) openmpi/4.0.5     3) ucx/1.9.0


Currently Loaded Modules:
  1) CCEnv           (S)      5) StdEnv/2020     (S)   9) pmix/3.1.5
  2) CCconfig                 6) gcccore/.10.2.0 (H)  10) libfabric/1.10.1
  3) gentoo/2020     (S)      7) gcc/10.2.0      (t)  11) openmpi/4.0.5    (m)
  4) imkl/2020.1.217 (math)   8) ucx/1.9.0

  Where:
   H:     Hidden Module
   S:     Module is Sticky, requires --force to unload or purge
   m:     MPI implementations / Implémentations MPI
   math:  Mathematical libraries / Bibliothèques mathématiques
   t:     Tools for development / Outils de développement

 

Current working directory: /gpfs/fs0/scratch/m/mlafond/pasr1602/library
Starting run at: Tue Mar 23 19:58:50 EDT 2021
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 7 of 20 is on nia1378.scinet.local
rank 7 synchronised, num nodes = 19 
Exit tag received on process 7 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 0 of 20 is on nia0012.scinet.local
Seed sent 
Termination achieved: nodes 19, busy 0 
solution NOT received from rank 1
solution NOT received from rank 2
solution NOT received from rank 3
solution NOT received from rank 4
solution NOT received from rank 5
solution NOT received from rank 6
solution NOT received from rank 7
solution NOT received from rank 8
solution received from 9, Bytes : 2164, refVal 268 
solution NOT received from rank 10
solution NOT received from rank 11
solution NOT received from rank 12
solution NOT received from rank 13
solution NOT received from rank 14
solution received from 15, Bytes : 2148, refVal 264 
solution NOT received from rank 16
solution NOT received from rank 17
solution NOT received from rank 18
solution NOT received from rank 19

 
 
*****************************************************
Elapsed time : 96.524 
Total number of requests : 631270 
Number of approved requests : 73155 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 14 of 20 is on nia1482.scinet.local
rank 14 synchronised, num nodes = 19 
Exit tag received on process 14 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 13 of 20 is on nia1481.scinet.local
rank 13 synchronised, num nodes = 19 
Exit tag received on process 13 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 18 of 20 is on nia1488.scinet.local
rank 18 synchronised, num nodes = 19 
Exit tag received on process 18 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 10 of 20 is on nia1477.scinet.local
rank 10 synchronised, num nodes = 19 
Exit tag received on process 10 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 16 of 20 is on nia1485.scinet.local
rank 16 synchronised, num nodes = 19 
Exit tag received on process 16 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 15 of 20 is on nia1484.scinet.local
rank 15 synchronised, num nodes = 19 
VC = 267....process 15, thread 25, Tue Mar 23 19:58:58 2021
rank 15 updated refValueGlobalAbsolute to 267 || 267 
rank 15, buffer size to be sent : 2160 
VC = 266....process 15, thread 37, Tue Mar 23 19:58:58 2021
rank 15 updated refValueGlobalAbsolute to 266 || 266 
rank 15, buffer size to be sent : 2156 
VC = 265....process 15, thread 35, Tue Mar 23 19:58:58 2021
rank 15 updated refValueGlobalAbsolute to 265 || 265 
rank 15, buffer size to be sent : 2152 
VC = 264....process 15, thread 35, Tue Mar 23 19:59:00 2021
rank 15 updated refValueGlobalAbsolute to 264 || 264 
rank 15, buffer size to be sent : 2148 
Exit tag received on process 15 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 12 of 20 is on nia1480.scinet.local
rank 12 synchronised, num nodes = 19 
Exit tag received on process 12 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 17 of 20 is on nia1487.scinet.local
rank 17 synchronised, num nodes = 19 
Exit tag received on process 17 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 11 of 20 is on nia1478.scinet.local
rank 11 synchronised, num nodes = 19 
Exit tag received on process 11 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 9 of 20 is on nia1380.scinet.local
rank 9 synchronised, num nodes = 19 
VC = 272......process 9, thread 0, Tue Mar 23 19:58:58 2021
rank 9 updated refValueGlobalAbsolute to 272 || 272 
rank 9, buffer size to be sent : 2180 
VC = 271.....process 9, thread 14, Tue Mar 23 19:58:58 2021
rank 9 updated refValueGlobalAbsolute to 271 || 271 
rank 9, buffer size to be sent : 2176 
VC = 270.....process 9, thread 37, Tue Mar 23 19:58:58 2021
rank 9 updated refValueGlobalAbsolute to 270 || 270 
rank 9, buffer size to be sent : 2172 
VC = 269......process 9, thread 2, Tue Mar 23 19:58:58 2021
rank 9 updated refValueGlobalAbsolute to 269 || 269 
rank 9, buffer size to be sent : 2168 
VC = 268.....process 9, thread 13, Tue Mar 23 19:58:58 2021
rank 9 updated refValueGlobalAbsolute to 268 || 268 
rank 9, buffer size to be sent : 2164 
Exit tag received on process 9 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 19 of 20 is on nia1489.scinet.local
rank 19 synchronised, num nodes = 19 
Exit tag received on process 19 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 8 of 20 is on nia1379.scinet.local
rank 8 synchronised, num nodes = 19 
Exit tag received on process 8 
Number of failed requests : 558115 
*****************************************************

 
 
Stream retrieved, size : 2148 
Cover size : 327 

Global pool idle time: 354.271282 seconds


argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 6 of 20 is on nia1310.scinet.local
rank 6 synchronised, num nodes = 19 
Exit tag received on process 6 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 4 of 20 is on nia1308.scinet.local
rank 4 synchronised, num nodes = 19 
Exit tag received on process 4 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 5 of 20 is on nia1309.scinet.local
rank 5 synchronised, num nodes = 19 
Exit tag received on process 5 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 3 of 20 is on nia1307.scinet.local
rank 3 synchronised, num nodes = 19 
Exit tag received on process 3 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 1 of 20 is on nia0074.scinet.local
rank 1 synchronised, num nodes = 19 
Exit tag received on process 1 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 2 of 20 is on nia1306.scinet.local
rank 2 synchronised, num nodes = 19 
Exit tag received on process 2 
Finishing run at: Tue Mar 23 20:00:36 EDT 2021

scontrol show jobid 5037775
JobId=5037775 JobName=0600_93_20_nodes
   UserId=pasr1602(3102120) GroupId=mlafond(6054778) MCS_label=N/A
   Priority=1897057 Nice=0 Account=def-mlafond QOS=normal
   JobState=COMPLETING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:02:05 TimeLimit=03:00:00 TimeMin=N/A
   SubmitTime=2021-03-23T19:55:37 EligibleTime=2021-03-23T19:55:37
   AccrueTime=2021-03-23T19:55:37
   StartTime=2021-03-23T19:58:31 EndTime=2021-03-23T20:00:36 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2021-03-23T19:58:31
   Partition=compute AllocNode:Sid=nia-login02:120347
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=nia[0012,0074,1306-1310,1378-1380,1477-1478,1480-1482,1484-1485,1487-1489]
   BatchHost=nia0012
   NumNodes=20 NumCPUs=1600 NumTasks=20 CPUs/Task=40 ReqB:S:C:T=0:0:*:*
   TRES=cpu=1600,mem=3500000M,node=20,billing=800
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=40 MinMemoryNode=175000M MinTmpDiskNode=0
   Features=[skylake|cascade] DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/fs0/scratch/m/mlafond/pasr1602/library/job.sh
   WorkDir=/gpfs/fs0/scratch/m/mlafond/pasr1602/library
   StdErr=/gpfs/fs0/scratch/m/mlafond/pasr1602/library/report/0600_93_20_nodes-5037775.out
   StdIn=/dev/null
   StdOut=/gpfs/fs0/scratch/m/mlafond/pasr1602/library/report/0600_93_20_nodes-5037775.out
   Power=
   MailUser=pasr1602@usherbrooke.ca MailType=BEGIN,END,FAIL,REQUEUE

sacct -j 5037775
       JobID    JobName    Account    Elapsed  MaxVMSize     MaxRSS  SystemCPU    UserCPU ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- ---------- ---------- -------- 
5037775      0600_93_2+ def-mlafo+   00:02:06                        07:58.857   13:33:06      0:0 
5037775.bat+      batch def-mlafo+   00:02:06                         00:00:00   00:00:00      0:0 
5037775.ext+     extern def-mlafo+   00:02:06                         00:00:00   00:00:00      0:0 
5037775.0         a.out def-mlafo+   00:01:46   3172276K    435148K  07:58.857   13:33:06      0:0 

kernel messages produced during job executions:
[Mar23 19:15] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288e8
[  +0.010781] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288e9
[  +0.010777] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288ea
[  +0.010775] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288eb
[  +0.010774] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288ec
[  +0.010774] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288ed
[  +0.010774] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288ee
[  +0.010775] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288ef
[  +0.010774] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288f0
[  +0.010775] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288f1
[  +0.010773] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288f2
[  +0.010774] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288f3
[  +0.010775] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288f4
[  +0.010773] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288f5
[  +0.010772] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288f6
[  +0.011471] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288f7
[  +0.011353] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288f8
[  +0.011273] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288f9
[  +0.011255] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288fa
[  +0.011234] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288fb
[  +0.073358] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288d4
[  +0.011238] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288d5
[  +0.011198] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288d6
[  +0.011183] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288d7
[  +0.011167] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288d8
[  +0.011148] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288d9
[  +0.011138] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288da
[  +0.011121] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288db
[  +0.011100] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288dc
[  +0.011087] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288fc
[  +0.011084] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288fd
[  +0.011067] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288fe
[  +0.011062] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x288ff
[  +0.011036] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x28900
[  +0.011025] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x28901
[  +0.011008] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x28902
[  +0.010987] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x28903
[  +0.010971] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x28904
[  +0.010954] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x28905
[  +0.010940] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x28906


Lmod is automatically replacing "intel/2020.1.217" with "gcc/10.2.0".


Inactive Modules:
  1) libfabric/1.10.1     2) openmpi/4.0.3     3) ucx/1.8.0

The following have been reloaded with a version change:
  1) gcccore/.9.3.0 => gcccore/.10.2.0


Activating Modules:
  1) libfabric/1.10.1     2) openmpi/4.0.5     3) ucx/1.9.0


Currently Loaded Modules:
  1) CCEnv           (S)      5) StdEnv/2020     (S)   9) pmix/3.1.5
  2) CCconfig                 6) gcccore/.10.2.0 (H)  10) libfabric/1.10.1
  3) gentoo/2020     (S)      7) gcc/10.2.0      (t)  11) openmpi/4.0.5    (m)
  4) imkl/2020.1.217 (math)   8) ucx/1.9.0

  Where:
   H:     Hidden Module
   S:     Module is Sticky, requires --force to unload or purge
   m:     MPI implementations / Implémentations MPI
   math:  Mathematical libraries / Bibliothèques mathématiques
   t:     Tools for development / Outils de développement

 

Current working directory: /gpfs/fs0/scratch/m/mlafond/pasr1602/library
Starting run at: Tue Mar 23 19:55:32 EDT 2021
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 6 of 10 is on nia1379.scinet.local
rank 6 synchronised, num nodes = 9 
Exit tag received on process 6 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 8 of 10 is on nia1477.scinet.local
rank 8 synchronised, num nodes = 9 
Exit tag received on process 8 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 7 of 10 is on nia1380.scinet.local
rank 7 synchronised, num nodes = 9 
VC = 273......process 7, thread 0, Tue Mar 23 19:55:43 2021
rank 7 updated refValueGlobalAbsolute to 273 || 273 
rank 7, buffer size to be sent : 2184 
VC = 271.....process 7, thread 21, Tue Mar 23 19:55:43 2021
rank 7 updated refValueGlobalAbsolute to 271 || 271 
rank 7, buffer size to be sent : 2176 
VC = 269.....process 7, thread 10, Tue Mar 23 19:55:43 2021
rank 7 updated refValueGlobalAbsolute to 269 || 269 
rank 7, buffer size to be sent : 2168 
VC = 268.....process 7, thread 24, Tue Mar 23 19:55:43 2021
rank 7 updated refValueGlobalAbsolute to 268 || 268 
rank 7, buffer size to be sent : 2164 
Exit tag received on process 7 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 9 of 10 is on nia1478.scinet.local
rank 9 synchronised, num nodes = 9 
VC = 272......process 9, thread 0, Tue Mar 23 19:55:43 2021
rank 9 updated refValueGlobalAbsolute to 272 || 272 
rank 9, buffer size to be sent : 2180 
Exit tag received on process 9 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 5 of 10 is on nia1378.scinet.local
rank 5 synchronised, num nodes = 9 
VC = 267......process 5, thread 2, Tue Mar 23 19:55:43 2021
rank 5 updated refValueGlobalAbsolute to 267 || 267 
rank 5, buffer size to be sent : 2160 
VC = 266......process 5, thread 4, Tue Mar 23 19:55:43 2021
rank 5 updated refValueGlobalAbsolute to 266 || 266 
rank 5, buffer size to be sent : 2156 
VC = 265.....process 5, thread 20, Tue Mar 23 19:55:43 2021
rank 5 updated refValueGlobalAbsolute to 265 || 265 
rank 5, buffer size to be sent : 2152 
VC = 264.....process 5, thread 20, Tue Mar 23 19:55:45 2021
rank 5 updated refValueGlobalAbsolute to 264 || 264 
rank 5, buffer size to be sent : 2148 
Exit tag received on process 5 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 0 of 10 is on nia1306.scinet.local
Seed sent 
Termination achieved: nodes 9, busy 0 
solution NOT received from rank 1
solution NOT received from rank 2
solution received from 3, Bytes : 2200, refVal 277 
solution NOT received from rank 4
solution received from 5, Bytes : 2148, refVal 264 
solution NOT received from rank 6
solution received from 7, Bytes : 2164, refVal 268 
solution NOT received from rank 8
solution received from 9, Bytes : 2180, refVal 272 

 
 
*****************************************************
Elapsed time : 165.515 
Total number of requests : 165257 
Number of approved requests : 25368 
Number of failed requests : 139889 
*****************************************************

 
 
Stream retrieved, size : 2148 
Cover size : 327 

Global pool idle time: 112.809794 seconds


argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 3 of 10 is on nia1309.scinet.local
rank 3 synchronised, num nodes = 9 
VC = 277......process 3, thread 0, Tue Mar 23 19:55:43 2021
rank 3 updated refValueGlobalAbsolute to 277 || 277 
rank 3, buffer size to be sent : 2200 
Exit tag received on process 3 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 4 of 10 is on nia1310.scinet.local
rank 4 synchronised, num nodes = 9 
Exit tag received on process 4 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 2 of 10 is on nia1308.scinet.local
rank 2 synchronised, num nodes = 9 
Exit tag received on process 2 
argc: 7, threads: 40, prob : 6, filename: input/prob_4/600/0600_93 
Process 1 of 10 is on nia1307.scinet.local
rank 1 synchronised, num nodes = 9 
Exit tag received on process 1 
Finishing run at: Tue Mar 23 19:58:29 EDT 2021

scontrol show jobid 5037774
JobId=5037774 JobName=0600_93_10_nodes
   UserId=pasr1602(3102120) GroupId=mlafond(6054778) MCS_label=N/A
   Priority=1896670 Nice=0 Account=def-mlafond QOS=normal
   JobState=COMPLETING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:03:09 TimeLimit=03:00:00 TimeMin=N/A
   SubmitTime=2021-03-23T19:55:19 EligibleTime=2021-03-23T19:55:19
   AccrueTime=2021-03-23T19:55:19
   StartTime=2021-03-23T19:55:20 EndTime=2021-03-23T19:58:29 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2021-03-23T19:55:20
   Partition=compute AllocNode:Sid=nia-login02:120347
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=nia[1306-1310,1378-1380,1477-1478]
   BatchHost=nia1306
   NumNodes=10 NumCPUs=800 NumTasks=10 CPUs/Task=40 ReqB:S:C:T=0:0:*:*
   TRES=cpu=800,mem=1750000M,node=10,billing=400
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=40 MinMemoryNode=175000M MinTmpDiskNode=0
   Features=[skylake|cascade] DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/fs0/scratch/m/mlafond/pasr1602/library/job.sh
   WorkDir=/gpfs/fs0/scratch/m/mlafond/pasr1602/library
   StdErr=/gpfs/fs0/scratch/m/mlafond/pasr1602/library/report/0600_93_10_nodes-5037774.out
   StdIn=/dev/null
   StdOut=/gpfs/fs0/scratch/m/mlafond/pasr1602/library/report/0600_93_10_nodes-5037774.out
   Power=
   MailUser=pasr1602@usherbrooke.ca MailType=BEGIN,END,FAIL,REQUEUE

sacct -j 5037774
       JobID    JobName    Account    Elapsed  MaxVMSize     MaxRSS  SystemCPU    UserCPU ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- ---------- ---------- -------- 
5037774      0600_93_1+ def-mlafo+   00:03:09                        06:12.805   12:55:06      0:0 
5037774.bat+      batch def-mlafo+   00:03:09   1057400K      9540K  00:01.332  00:03.589      0:0 
5037774.ext+     extern def-mlafo+   00:03:09    138360K      1068K  00:00.001  00:00.006      0:0 
5037774.0         a.out def-mlafo+   00:02:57   3235404K    438268K  06:11.471   12:55:02      0:0 

kernel messages produced during job executions:
[Mar23 18:36] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147ea
[  +0.013197] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147eb
[  +0.012422] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147ec
[  +0.012492] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147ed
[  +0.012257] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147ee
[  +0.011974] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147ef
[  +0.012044] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147f0
[  +0.012295] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147f1
[  +0.012210] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147f2
[  +0.011860] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147f3
[  +0.033355] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147d8
[  +0.012114] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147d9
[  +0.012314] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147da
[  +0.011897] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147db
[  +0.012380] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147dc
[  +0.011943] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147dd
[  +0.011991] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147de
[  +0.011914] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147f4
[  +0.012385] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147f5
[  +0.012166] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x147f6

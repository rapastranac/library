
Lmod is automatically replacing "intel/2020.1.217" with "gcc/10.2.0".


Inactive Modules:
  1) libfabric/1.10.1     2) openmpi/4.0.3     3) ucx/1.8.0

The following have been reloaded with a version change:
  1) gcccore/.9.3.0 => gcccore/.10.2.0


Activating Modules:
  1) libfabric/1.10.1     2) openmpi/4.0.5     3) ucx/1.9.0


Currently Loaded Modules:
  1) CCEnv           (S)      5) StdEnv/2020     (S)   9) pmix/3.1.5
  2) CCconfig                 6) gcccore/.10.2.0 (H)  10) libfabric/1.10.1
  3) gentoo/2020     (S)      7) gcc/10.2.0      (t)  11) openmpi/4.0.5    (m)
  4) imkl/2020.1.217 (math)   8) ucx/1.9.0

  Where:
   H:     Hidden Module
   S:     Module is Sticky, requires --force to unload or purge
   m:     MPI implementations / Implémentations MPI
   math:  Mathematical libraries / Bibliothèques mathématiques
   t:     Tools for development / Outils de développement

 

Current working directory: /gpfs/fs0/scratch/m/mlafond/pasr1602/library
Starting run at: Tue Mar 23 18:17:24 EDT 2021
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 0 of 20 is on nia0054.scinet.local
Seed sent 
Termination achieved: nodes 19, busy 0 
solution received from 1, Bytes : 3960, refVal 970 
solution NOT received from rank 2
solution received from 3, Bytes : 4016, refVal 984 
solution received from 4, Bytes : 3936, refVal 964 
solution NOT received from rank 5
solution NOT received from rank 6
solution NOT received from rank 7
solution received from 8, Bytes : 3976, refVal 974 
solution received from 9, Bytes : 3956, refVal 969 
solution NOT received from rank 10
solution received from 11, Bytes : 4012, refVal 983 
solution NOT received from rank 12
solution received from 13, Bytes : 3928, refVal 962 
solution received from 14, Bytes : 3868, refVal 947 
solution received from 15, Bytes : 3972, refVal 973 
solution received from 16, Bytes : 3864, refVal 946 
solution NOT received from rank 17
solution NOT received from rank 18
solution received from 19, Bytes : 3948, refVal 967 

 
 
*****************************************************
Elapsed time : 4564.476 
Total number of requests : 17105039 
Number of approved requests : 1875135 
Number of failed requests : 15229904 
*****************************************************

 
 
Stream retrieved, size : 3864 
Cover size : 946 

Global pool idle time: 24401.030920 seconds


argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 17 of 20 is on nia1288.scinet.local
rank 17 synchronised, num nodes = 19 
Exit tag received on process 17 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 16 of 20 is on nia0876.scinet.local
rank 16 synchronised, num nodes = 19 
VC = 946....process 16, thread 12, Tue Mar 23 19:27:15 2021
rank 16 updated refValueGlobalAbsolute to 946 || 946 
rank 16, buffer size to be sent : 3864 
Exit tag received on process 16 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 15 of 20 is on nia0872.scinet.local
rank 15 synchronised, num nodes = 18 
VC = 973....process 15, thread 31, Tue Mar 23 18:17:35 2021
rank 15 updated refValueGlobalAbsolute to 973 || 973 
rank 15, buffer size to be sent : 3972 
Exit tag received on process 15 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 19 of 20 is on nia1290.scinet.local
rank 19 synchronised, num nodes = 18 
VC = 971....process 19, thread 28, Tue Mar 23 18:17:35 2021
rank 19 updated refValueGlobalAbsolute to 971 || 971 
rank 19, buffer size to be sent : 3964 
VC = 968....process 19, thread 21, Tue Mar 23 18:17:36 2021
rank 19 updated refValueGlobalAbsolute to 968 || 968 
rank 19, buffer size to be sent : 3952 
VC = 967....process 19, thread 21, Tue Mar 23 18:17:36 2021
rank 19 updated refValueGlobalAbsolute to 967 || 967 
rank 19, buffer size to be sent : 3948 
Exit tag received on process 19 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 18 of 20 is on nia1289.scinet.local
rank 18 synchronised, num nodes = 18 
Exit tag received on process 18 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 13 of 20 is on nia0806.scinet.local
rank 13 synchronised, num nodes = 19 
VC = 962.....process 13, thread 6, Tue Mar 23 18:17:36 2021
rank 13 updated refValueGlobalAbsolute to 962 || 962 
rank 13, buffer size to be sent : 3928 
Exit tag received on process 13 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 12 of 20 is on nia0768.scinet.local
rank 12 synchronised, num nodes = 19 
Exit tag received on process 12 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 11 of 20 is on nia0764.scinet.local
rank 11 synchronised, num nodes = 18 
VC = 983.....process 11, thread 0, Tue Mar 23 18:17:35 2021
rank 11 updated refValueGlobalAbsolute to 983 || 983 
rank 11, buffer size to be sent : 4012 
Exit tag received on process 11 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 8 of 20 is on nia0556.scinet.local
rank 8 synchronised, num nodes = 19 
VC = 980......process 8, thread 0, Tue Mar 23 18:17:35 2021
rank 8 updated refValueGlobalAbsolute to 980 || 980 
rank 8, buffer size to be sent : 4000 
VC = 979.....process 8, thread 15, Tue Mar 23 18:17:35 2021
rank 8 updated refValueGlobalAbsolute to 979 || 979 
rank 8, buffer size to be sent : 3996 
VC = 974.....process 8, thread 22, Tue Mar 23 18:17:35 2021
rank 8 updated refValueGlobalAbsolute to 974 || 974 
rank 8, buffer size to be sent : 3976 
Exit tag received on process 8 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 10 of 20 is on nia0699.scinet.local
rank 10 synchronised, num nodes = 18 
Exit tag received on process 10 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 9 of 20 is on nia0681.scinet.local
rank 9 synchronised, num nodes = 19 
VC = 977.....process 9, thread 22, Tue Mar 23 18:17:35 2021
rank 9 updated refValueGlobalAbsolute to 977 || 977 
rank 9, buffer size to be sent : 3988 
VC = 976.....process 9, thread 29, Tue Mar 23 18:17:35 2021
rank 9 updated refValueGlobalAbsolute to 976 || 976 
rank 9, buffer size to be sent : 3984 
VC = 975.....process 9, thread 26, Tue Mar 23 18:17:35 2021
rank 9 updated refValueGlobalAbsolute to 975 || 975 
rank 9, buffer size to be sent : 3980 
VC = 969.....process 9, thread 29, Tue Mar 23 18:17:36 2021
rank 9 updated refValueGlobalAbsolute to 969 || 969 
rank 9, buffer size to be sent : 3956 
Exit tag received on process 9 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 14 of 20 is on nia0855.scinet.local
rank 14 synchronised, num nodes = 19 
VC = 961....process 14, thread 39, Tue Mar 23 18:17:37 2021
rank 14 updated refValueGlobalAbsolute to 961 || 961 
rank 14, buffer size to be sent : 3924 
VC = 949....process 14, thread 16, Tue Mar 23 18:17:51 2021
rank 14 updated refValueGlobalAbsolute to 949 || 949 
rank 14, buffer size to be sent : 3876 
VC = 948....process 14, thread 16, Tue Mar 23 18:17:59 2021
rank 14 updated refValueGlobalAbsolute to 948 || 948 
rank 14, buffer size to be sent : 3872 
VC = 947....process 14, thread 16, Tue Mar 23 18:26:26 2021
rank 14 updated refValueGlobalAbsolute to 947 || 947 
rank 14, buffer size to be sent : 3868 
Exit tag received on process 14 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 7 of 20 is on nia0548.scinet.local
rank 7 synchronised, num nodes = 18 
Exit tag received on process 7 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 6 of 20 is on nia0525.scinet.local
rank 6 synchronised, num nodes = 18 
Exit tag received on process 6 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 5 of 20 is on nia0517.scinet.local
rank 5 synchronised, num nodes = 19 
Exit tag received on process 5 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 2 of 20 is on nia0204.scinet.local
rank 2 synchronised, num nodes = 18 
Exit tag received on process 2 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 1 of 20 is on nia0144.scinet.local
rank 1 synchronised, num nodes = 19 
VC = 970.....process 1, thread 32, Tue Mar 23 18:17:35 2021
rank 1 updated refValueGlobalAbsolute to 970 || 970 
rank 1, buffer size to be sent : 3960 
Exit tag received on process 1 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 4 of 20 is on nia0280.scinet.local
rank 4 synchronised, num nodes = 19 
VC = 965......process 4, thread 5, Tue Mar 23 18:17:36 2021
rank 4 updated refValueGlobalAbsolute to 965 || 965 
rank 4, buffer size to be sent : 3940 
VC = 964......process 4, thread 5, Tue Mar 23 18:17:36 2021
rank 4 updated refValueGlobalAbsolute to 964 || 964 
rank 4, buffer size to be sent : 3936 
Exit tag received on process 4 
argc: 7, threads: 40, prob : 90, filename: input/p_hat1000_2 
Process 3 of 20 is on nia0244.scinet.local
rank 3 synchronised, num nodes = 18 
VC = 984......process 3, thread 0, Tue Mar 23 18:17:35 2021
rank 3 updated refValueGlobalAbsolute to 984 || 984 
rank 3, buffer size to be sent : 4016 
Exit tag received on process 3 
Finishing run at: Tue Mar 23 19:33:42 EDT 2021

scontrol show jobid 5037571
JobId=5037571 JobName=p_hat1000_2_20nodes
   UserId=pasr1602(3102120) GroupId=mlafond(6054778) MCS_label=N/A
   Priority=1947317 Nice=0 Account=def-mlafond QOS=normal
   JobState=COMPLETING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=01:16:40 TimeLimit=03:00:00 TimeMin=N/A
   SubmitTime=2021-03-23T18:08:26 EligibleTime=2021-03-23T18:08:26
   AccrueTime=2021-03-23T18:08:26
   StartTime=2021-03-23T18:17:03 EndTime=2021-03-23T19:33:43 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2021-03-23T18:17:03
   Partition=compute AllocNode:Sid=nia-login03:248058
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=nia[0054,0144,0204,0244,0280,0517,0525,0548,0556,0681,0699,0764,0768,0855,0872,0876,1288-1290]
   BatchHost=nia0054
   NumNodes=19 NumCPUs=1600 NumTasks=20 CPUs/Task=40 ReqB:S:C:T=0:0:*:*
   TRES=cpu=1600,mem=3500000M,node=20,billing=800
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=40 MinMemoryNode=175000M MinTmpDiskNode=0
   Features=[skylake|cascade] DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/fs0/scratch/m/mlafond/pasr1602/library/job.sh
   WorkDir=/gpfs/fs0/scratch/m/mlafond/pasr1602/library
   StdErr=/gpfs/fs0/scratch/m/mlafond/pasr1602/library/report/p_hat1000_2_20nodes-5037571.out
   StdIn=/dev/null
   StdOut=/gpfs/fs0/scratch/m/mlafond/pasr1602/library/report/p_hat1000_2_20nodes-5037571.out
   Power=
   MailUser=pasr1602@usherbrooke.ca MailType=BEGIN,END,FAIL,REQUEUE

sacct -j 5037571
       JobID    JobName    Account    Elapsed  MaxVMSize     MaxRSS  SystemCPU    UserCPU ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- ---------- ---------- -------- 
5037571      p_hat1000+ def-mlafo+   01:16:40                         13:35:15 19-23:36:+      0:0 
5037571.bat+      batch def-mlafo+   01:16:40   1723044K     10200K  00:01.354  00:03.675      0:0 
5037571.ext+     extern def-mlafo+   01:16:40    138360K      1068K  00:00.006  00:00.010      0:0 
5037571.0         a.out def-mlafo+   01:16:17  13488716K  11053988K   13:35:13 19-23:36:+      0:0 

kernel messages produced during job executions:
[Mar23 17:17] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdcb
[  +0.011712] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdcc
[  +0.011635] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdcd
[  +0.011550] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdce
[  +0.011533] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdcf
[  +0.011507] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdd0
[  +0.011485] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdd1
[  +0.011470] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdd2
[  +0.011449] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdd3
[  +0.011427] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdd4
[  +0.011406] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdd5
[  +0.011380] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdd6
[  +0.011361] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdd7
[  +0.011353] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdd8
[  +0.011332] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdd9
[  +0.011312] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdda
[  +0.011285] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fddb
[  +0.011264] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fddc
[  +0.011242] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fddd
[  +0.011238] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdde
[  +0.047074] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdb7
[  +0.011204] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdb8
[  +0.011184] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdb9
[  +0.011153] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdba
[  +0.011131] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdbb
[  +0.011126] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdbc
[  +0.011109] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdbd
[  +0.011083] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdbe
[  +0.011063] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fdbf
[  +0.011039] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fddf
[  +0.011017] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fde0
[  +0.010995] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fde1
[  +0.010965] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fde2
[  +0.010951] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fde3
[  +0.010936] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fde4
[  +0.010933] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fde5
[  +0.010933] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fde6
[  +0.010932] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fde7
[  +0.010917] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fde8
[  +0.010914] mlx5_core 0000:06:00.0: mlx5_core_get_rsc:63:(pid 0): Async event for bogus resource 0x1fde9
